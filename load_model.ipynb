{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Numpy\n",
    "import numpy as np\n",
    "# Pillow\n",
    "from PIL import Image\n",
    "# Torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and validate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "#             test_loss += F.nll_loss(output, torch.argmax(target.long(), 1), reduction='sum').item()  # sum up batch loss\n",
    "#             pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            \n",
    "            test_loss += nn.CrossEntropyLoss()(output, torch.argmax(target.long(), 1)).item()\n",
    "#             print(f\"This is test_loss: {test_loss}\")\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "#             print(f\"This is pred: {pred}\")\n",
    "#             print(torch.argmax(target, 1))\n",
    "#             print(pred.eq(torch.argmax(target, 1).view_as(pred)).sum().item())\n",
    "\n",
    "#             correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            correct += pred.eq(torch.argmax(target, 1).view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "  \n",
    "    return 100. * correct / len(test_loader.dataset), test_loss\n",
    "\n",
    "\n",
    "def validate(model, device, val_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "#             test_loss += F.nll_loss(output, torch.argmax(target.long(), 1), reduction='sum').item()  # sum up batch loss\n",
    "#             pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            \n",
    "            val_loss += nn.CrossEntropyLoss()(output, torch.argmax(target.long(), 1)).item()\n",
    "#             print(f\"This is test_loss: {test_loss}\")\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "#             print(f\"This is pred: {pred}\")\n",
    "#             print(torch.argmax(target, 1))\n",
    "#             print(pred.eq(torch.argmax(target, 1).view_as(pred)).sum().item())\n",
    "\n",
    "#             correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            correct += pred.eq(torch.argmax(target, 1).view_as(pred)).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        val_loss, correct, len(val_loader.dataset),\n",
    "        100. * correct / len(val_loader.dataset)))\n",
    "    \n",
    "    return 100. * correct / len(val_loader.dataset), val_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lung_Test_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor for generic Dataset class - simply assembles\n",
    "        the important parameters in attributes.\n",
    "        \"\"\"\n",
    "        \n",
    "        # All images are of size 150 x 150\n",
    "        self.img_size = (150, 150)\n",
    "        \n",
    "        # Three classes will be considered here (normal, infected and covid)\n",
    "        self.classes = {0: 'normal', 1: 'infected', 2: 'covid'}\n",
    "        \n",
    "        # The dataset consists only of test images\n",
    "        self.groups = 'test'\n",
    "        \n",
    "        # Number of images in each part of the dataset\n",
    "        self.dataset_numbers = {'test_normal': 234,\\\n",
    "                                'test_infected': 242, \\\n",
    "                                'test_covid': 138}\n",
    "        \n",
    "        # Path to images for different parts of the dataset\n",
    "        self.dataset_paths = {'test_normal': './dataset/test/normal/',\\\n",
    "                              'test_infected': './dataset/test/infected/non-covid', \\\n",
    "                              'test_covid': './dataset/test/infected/covid/'}\n",
    "        \n",
    "        \n",
    "    def describe(self):\n",
    "        \"\"\"\n",
    "        Descriptor function.\n",
    "        Will print details about the dataset when called.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate description\n",
    "        msg = \"This is the test dataset of the Lung Dataset\"\n",
    "        msg += \" used for the Small Project in the 50.039 Deep Learning class\"\n",
    "        msg += \" in Feb-March 2021. \\n\"\n",
    "        msg += \"It contains a total of {} images, \".format(sum(self.dataset_numbers.values()))\n",
    "        msg += \"of size {} by {}.\\n\".format(self.img_size[0], self.img_size[1])\n",
    "        msg += \"The images are stored in the following locations \"\n",
    "        msg += \"and each one contains the following number of images:\\n\"\n",
    "        for key, val in self.dataset_paths.items():\n",
    "            msg += \" - {}, in folder {}: {} images.\\n\".format(key, val, self.dataset_numbers[key])\n",
    "        print(msg)\n",
    "        \n",
    "    \n",
    "    def open_img(self, group_val, class_val, index_val):\n",
    "        \"\"\"\n",
    "        Opens image with specified parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        - group_val should take values in 'train', 'test' or 'val'.\n",
    "        - class_val variable should be set to 'normal', 'infected' or 'covid'.\n",
    "        - index_val should be an integer with values between 0 and the maximal number of images in dataset.\n",
    "        \n",
    "        Returns loaded image as a normalized Numpy array.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Asserts checking for consistency in passed parameters\n",
    "        err_msg = \"Error - group_val variable should be set to 'train', 'test' or 'val'.\"\n",
    "        assert group_val in self.groups, err_msg\n",
    "        \n",
    "        err_msg = \"Error - class_val variable should be set to 'normal', 'infected' or 'covid'.\"\n",
    "        assert class_val in self.classes.values(), err_msg\n",
    "        \n",
    "        max_val = self.dataset_numbers['{}_{}'.format(group_val, class_val)]\n",
    "        err_msg = \"Error - index_val variable should be an integer between 0 and the maximal number of images.\"\n",
    "        err_msg += \"\\n(In {}/{}, you have {} images.)\".format(group_val, class_val, max_val)\n",
    "        assert isinstance(index_val, int), err_msg\n",
    "        assert index_val >= 0 and index_val <= max_val, err_msg\n",
    "        \n",
    "        # Open file as before\n",
    "        path_to_file = '{}/{}.jpg'.format(self.dataset_paths['{}_{}'.format(group_val, class_val)], index_val)\n",
    "        with open(path_to_file, 'rb') as f:\n",
    "            im = np.asarray(Image.open(f))/255\n",
    "        f.close()\n",
    "        return im\n",
    "    \n",
    "    \n",
    "    def show_img(self, group_val, class_val, index_val):\n",
    "        \"\"\"\n",
    "        Opens, then displays image with specified parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        - group_val should take values in 'train', 'test' or 'val'.\n",
    "        - class_val variable should be set to 'normal' or 'infected'.\n",
    "        - index_val should be an integer with values between 0 and the maximal number of images in dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Open image\n",
    "        im = self.open_img(group_val, class_val, index_val)\n",
    "        \n",
    "        # Display\n",
    "        plt.imshow(im)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Length special method, returns the number of images in dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Length function\n",
    "        return sum(self.dataset_numbers.values())\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Getitem special method.\n",
    "        \n",
    "        Expects an integer value index, between 0 and len(self) - 1.\n",
    "        \n",
    "        Returns the image and its label as a one hot vector, both\n",
    "        in torch tensor format in dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get item special method\n",
    "        first_val = int(list(self.dataset_numbers.values())[0])\n",
    "        second_val = first_val + int(list(self.dataset_numbers.values())[1])\n",
    "        if index < first_val:\n",
    "            class_val = 'normal'\n",
    "            label = torch.Tensor([1, 0, 0])\n",
    "        elif index >= first_val and index < second_val:\n",
    "            class_val = 'infected'\n",
    "            index = index - first_val\n",
    "            label = torch.Tensor([0, 1, 0])\n",
    "        else:\n",
    "            class_val = 'covid'\n",
    "            index = index - second_val\n",
    "            label = torch.Tensor([0, 0, 1])\n",
    "        im = self.open_img(self.groups, class_val, index)\n",
    "        im = transforms.functional.to_tensor(np.array(im)).float()\n",
    "        return im, label\n",
    "    \n",
    "    \n",
    "class Lung_Val_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor for generic Dataset class - simply assembles\n",
    "        the important parameters in attributes.\n",
    "        \"\"\"\n",
    "        \n",
    "        # All images are of size 150 x 150\n",
    "        self.img_size = (150, 150)\n",
    "        \n",
    "        # Three classes will be considered here (normal, infected and covid)\n",
    "        self.classes = {0: 'normal', 1: 'infected', 2: 'covid'}\n",
    "        \n",
    "        # The dataset consists only of validation images\n",
    "        self.groups = 'val'\n",
    "        \n",
    "        # Number of images in each part of the dataset\n",
    "        self.dataset_numbers = {'val_normal': 8,\\\n",
    "                                'val_infected': 8, \\\n",
    "                                'val_covid': 8}\n",
    "        \n",
    "        # Path to images for different parts of the dataset\n",
    "        self.dataset_paths = {'val_normal': './dataset/val/normal/',\\\n",
    "                              'val_infected': './dataset/val/infected/non-covid/', \\\n",
    "                              'val_covid': './dataset/val/infected/covid'}\n",
    "        \n",
    "        \n",
    "    def describe(self):\n",
    "        \"\"\"\n",
    "        Descriptor function.\n",
    "        Will print details about the dataset when called.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate description\n",
    "        msg = \"This is the validation dataset of the Lung Dataset\"\n",
    "        msg += \" used for the Small Project in the 50.039 Deep Learning class\"\n",
    "        msg += \" in Feb-March 2021. \\n\"\n",
    "        msg += \"It contains a total of {} images, \".format(sum(self.dataset_numbers.values()))\n",
    "        msg += \"of size {} by {}.\\n\".format(self.img_size[0], self.img_size[1])\n",
    "        msg += \"The images are stored in the following locations \"\n",
    "        msg += \"and each one contains the following number of images:\\n\"\n",
    "        for key, val in self.dataset_paths.items():\n",
    "            msg += \" - {}, in folder {}: {} images.\\n\".format(key, val, self.dataset_numbers[key])\n",
    "        print(msg)\n",
    "        \n",
    "    \n",
    "    def open_img(self, group_val, class_val, index_val):\n",
    "        \"\"\"\n",
    "        Opens image with specified parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        - group_val should take values in 'train', 'test' or 'val'.\n",
    "        - class_val variable should be set to 'normal' or 'infected' or 'covid'.\n",
    "        - index_val should be an integer with values between 0 and the maximal number of images in dataset.\n",
    "        \n",
    "        Returns loaded image as a normalized Numpy array.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Asserts checking for consistency in passed parameters\n",
    "        err_msg = \"Error - group_val variable should be set to 'train', 'test' or 'val'.\"\n",
    "        assert group_val in self.groups, err_msg\n",
    "        \n",
    "        err_msg = \"Error - class_val variable should be set to 'normal' or 'infected' or 'covid'.\"\n",
    "        assert class_val in self.classes.values(), err_msg\n",
    "        \n",
    "        max_val = self.dataset_numbers['{}_{}'.format(group_val, class_val)]\n",
    "        err_msg = \"Error - index_val variable should be an integer between 0 and the maximal number of images.\"\n",
    "        err_msg += \"\\n(In {}/{}, you have {} images.)\".format(group_val, class_val, max_val)\n",
    "        assert isinstance(index_val, int), err_msg\n",
    "        assert index_val >= 0 and index_val <= max_val, err_msg\n",
    "        \n",
    "        # Open file as before\n",
    "        path_to_file = '{}/{}.jpg'.format(self.dataset_paths['{}_{}'.format(group_val, class_val)], index_val)\n",
    "        with open(path_to_file, 'rb') as f:\n",
    "            im = np.asarray(Image.open(f))/255\n",
    "        f.close()\n",
    "        return im\n",
    "    \n",
    "    \n",
    "    def show_img(self, group_val, class_val, index_val):\n",
    "        \"\"\"\n",
    "        Opens, then displays image with specified parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        - group_val should take values in 'train', 'test' or 'val'.\n",
    "        - class_val variable should be set to 'normal' or 'infected' or 'covid'.\n",
    "        - index_val should be an integer with values between 0 and the maximal number of images in dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Open image\n",
    "        im = self.open_img(group_val, class_val, index_val)\n",
    "        \n",
    "        # Display\n",
    "        plt.imshow(im)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Length special method, returns the number of images in dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Length function\n",
    "        return sum(self.dataset_numbers.values())\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Getitem special method.\n",
    "        \n",
    "        Expects an integer value index, between 0 and len(self) - 1.\n",
    "        \n",
    "        Returns the image and its label as a one hot vector, both\n",
    "        in torch tensor format in dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get item special method\n",
    "        first_val = int(list(self.dataset_numbers.values())[0])\n",
    "        second_val = first_val + int(list(self.dataset_numbers.values())[1])\n",
    "        if index < first_val:\n",
    "            class_val = 'normal'\n",
    "            label = torch.Tensor([1, 0, 0])\n",
    "        elif index >= first_val and index < second_val:\n",
    "            class_val = 'infected'\n",
    "            index = index - first_val\n",
    "            label = torch.Tensor([0, 1, 0])\n",
    "        else:\n",
    "            class_val = 'covid'\n",
    "            index = index - second_val\n",
    "            label = torch.Tensor([0, 0, 1])\n",
    "        im = self.open_img(self.groups, class_val, index)\n",
    "        im = transforms.functional.to_tensor(np.array(im)).float()\n",
    "        return im, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the test dataset of the Lung Dataset used for the Small Project in the 50.039 Deep Learning class in Feb-March 2021. \n",
      "It contains a total of 614 images, of size 150 by 150.\n",
      "The images are stored in the following locations and each one contains the following number of images:\n",
      " - test_normal, in folder ./dataset/test/normal/: 234 images.\n",
      " - test_infected, in folder ./dataset/test/infected/non-covid: 242 images.\n",
      " - test_covid, in folder ./dataset/test/infected/covid/: 138 images.\n",
      "\n",
      "This is the validation dataset of the Lung Dataset used for the Small Project in the 50.039 Deep Learning class in Feb-March 2021. \n",
      "It contains a total of 24 images, of size 150 by 150.\n",
      "The images are stored in the following locations and each one contains the following number of images:\n",
      " - val_normal, in folder ./dataset/val/normal/: 8 images.\n",
      " - val_infected, in folder ./dataset/val/infected/non-covid/: 8 images.\n",
      " - val_covid, in folder ./dataset/val/infected/covid: 8 images.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ld_test = Lung_Test_Dataset()\n",
    "ld_test.describe()\n",
    "\n",
    "ld_val = Lung_Val_Dataset()\n",
    "ld_val.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(663552, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"Input:\", x.shape)\n",
    "        x = self.conv1(x)\n",
    "        #print(\"After conv1:\", x.shape)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.conv2(x)\n",
    "        #print(\"After conv2:\", x.shape)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        #print(\"After max_pool2d:\", x.shape)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "#         print(\"After flatten:\", x.shape)\n",
    "        x = self.fc1(x)\n",
    "        #print(\"After fc1:\", x.shape)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        #print(\"After fc2:\", x.shape)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        #print(\"Output:\", output.shape)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5031, Accuracy: 407/614 (66%)\n",
      "\n",
      "\n",
      "Validation set: Average loss: 0.2849, Accuracy: 11/24 (46%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class args:\n",
    "  batch_size = 16 #'input batch size for training (default: 32)')\n",
    "  test_batch_size = 1000 #'input batch size for testing (default: 1000)')\n",
    "  epochs = 20 #'number of epochs to train (default: 14)') # 9~10 is good actually\n",
    "  lr = 0.8 #'learning rate (default: 1.0)')\n",
    "  gamma = 0.7 #'Learning rate step gamma (default: 0.7)')\n",
    "  no_cuda = False #'disables CUDA training')\n",
    "  dry_run = False #'quickly check a single pass')\n",
    "  seed = 1 #'random seed (default: 1)')\n",
    "  log_interval = 1000 #'how many batches to wait before logging training status')\n",
    "  save_model = True #'For Saving the current Model')\n",
    "    \n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "model_path = 'cnn_epoch7_71percentValAcc.pt'\n",
    "\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "#model = torch.load(model_path)\n",
    "\n",
    "bs_val = 4\n",
    "# Dataloader from dataset (test and val)\n",
    "test_loader = DataLoader(ld_test, batch_size = bs_val, shuffle = True)\n",
    "val_loader = DataLoader(ld_val, batch_size = bs_val, shuffle = True)\n",
    "\n",
    "val_loss_list = []\n",
    "val_accuracy_list = []\n",
    "test_loss_list = []\n",
    "test_accuracy_list = []\n",
    "\n",
    "test_accuracy, test_loss = test(model, device, test_loader)\n",
    "test_loss_list.append(test_loss)\n",
    "test_accuracy_list.append(test_accuracy)\n",
    "\n",
    "val_accuracy, val_loss = validate(model, device, val_loader)\n",
    "val_loss_list.append(val_loss)\n",
    "val_accuracy_list.append(val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
